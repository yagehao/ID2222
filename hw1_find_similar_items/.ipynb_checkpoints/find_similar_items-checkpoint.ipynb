{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original dataset: Opinosis Opinion ‚ÅÑ Review Data Set https://archive.ics.uci.edu/ml/datasets/Opinosis+Opinion+%26frasl%3B+Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import itertools\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 text files we choose to use\n",
    "file_list = ['battery-life_amazon_kindle',\n",
    "            'battery-life_ipod_nano_8gb',\n",
    "            'location_bestwestern_hotel_sfo',\n",
    "            'location_holiday_inn_london',\n",
    "            'price_amazon_kindle',\n",
    "            'room_holiday_inn_london',\n",
    "            'rooms_bestwestern_hotel_sfo',\n",
    "            'screen_ipod_nano_8gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O function\n",
    "def import_dataset(file_name):\n",
    "    \"\"\"\n",
    "    input: file_name in file_list\n",
    "    \"\"\"\n",
    "    \n",
    "    dataFile = './dataset/' + str(file_name) + '.txt.data'\n",
    "    with open(dataFile, 'rb') as f:\n",
    "        contents = []\n",
    "        for line in f.readlines():\n",
    "            contents.append(line.strip().decode('utf-8'))\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset\n",
      "document number:8\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "print('Importing dataset')\n",
    "\n",
    "dataset = [] # 8-entry list, each corresponding to a file\n",
    "for file_name in file_list:\n",
    "    contents = import_dataset(file_name)\n",
    "    dataset.append(contents)\n",
    "    \n",
    "print('document number:' + str(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function constructs k-shingles from a given text\n",
    "def shingle(text, k=5):\n",
    "    \"\"\"\n",
    "    input: text in dataset\n",
    "            k, shingle size.\n",
    "    \"\"\"\n",
    "    \n",
    "    # split the string into separate words\n",
    "    split_text = []\n",
    "    for review in text:\n",
    "        exclude = set(string.punctuation)\n",
    "        review = ''.join(ch for ch in review if ch not in exclude) # remove punctuation\n",
    "        review = review.lower() # convert all characters into lower characters\n",
    "        for word in review.split():\n",
    "            split_text.append(word)\n",
    "            \n",
    "    # k-shingle\n",
    "    shingle_list = []\n",
    "    for i in range(len(split_text)-k+1):\n",
    "        shingle_list.append(split_text[i:i+k])\n",
    "\n",
    "    # remove duplicates\n",
    "    shingle_list = list(dict.fromkeys(shingle_list))\n",
    "    \n",
    "    # each sublist in shingle_no_dup represents a shingle\n",
    "    # convert the sublist into a string\n",
    "    shingle_strings = []\n",
    "    for index, shingle in enumerate(shingle_no_dup):\n",
    "        sum_string = shingle[0]\n",
    "        for i in range(1, len(shingle)):\n",
    "            sum_string = sum_string + ' ' + shingle[i]\n",
    "        shingle_strings.append(sum_string)\n",
    "        \n",
    "    return shingle_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shingling\n",
      "number of shingles in document 1 is 1771\n",
      "number of shingles in document 2 is 1136\n",
      "number of shingles in document 3 is 5045\n",
      "number of shingles in document 4 is 6165\n",
      "number of shingles in document 5 is 1941\n",
      "number of shingles in document 6 is 11948\n",
      "number of shingles in document 7 is 4540\n",
      "number of shingles in document 8 is 1043\n"
     ]
    }
   ],
   "source": [
    "# shingling all 8 texts\n",
    "print('Shingling')\n",
    "\n",
    "shingle_texts = []\n",
    "for text in dataset:\n",
    "    shingle_texts.append(shingle(text))\n",
    "    \n",
    "for i in range(len(shingle_texts)):\n",
    "    num = len(shingle_texts[i])\n",
    "    print(f'number of shingles in document {i+1} is {num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of shingles: 33589\n",
      "number of unique shingles: 32678\n"
     ]
    }
   ],
   "source": [
    "# flatting the list of all shingles\n",
    "flat_shingle_texts = np.hstack(np.array(shingle_texts))\n",
    "print('number of shingles:',flat_shingle_texts.shape[0])\n",
    "\n",
    "# get unique shingles\n",
    "unique_flat_shingle_texts = np.unique(flat_shingle_texts)\n",
    "max_value = unique_flat_shingle_texts.shape[0]\n",
    "print('number of unique shingles:', max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash unique shingles\n",
    "# build dictionary with {unique shingle: hash value}\n",
    "for i in range(len(unique_flat_shingle_texts)):\n",
    "    shingle_dict[unique_flat_shingle_texts[i]] = hash(unique_flat_shingle_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represents the document in the form of anordered set of its hashed k-shingles\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
