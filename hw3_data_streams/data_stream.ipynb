{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID2222 Homework 3: Mining Data Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hongyi Luo (hluo@kth.se) & Yage Hao (yage@kth.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset: https://snap.stanford.edu/data/web-Stanford.html \n",
    "\n",
    "***Dataset statistics***  \n",
    "Nodes\t281903  \n",
    "Edges\t2312497  \n",
    "Nodes in largest WCC\t255265 (0.906)  \n",
    "Edges in largest WCC\t2234572 (0.966)  \n",
    "Nodes in largest SCC\t150532 (0.534)  \n",
    "Edges in largest SCC\t1576314 (0.682)  \n",
    "Average clustering coefficient\t0.5976  \n",
    "Number of triangles\t11329473  \n",
    "Fraction of closed triangles\t0.002889  \n",
    "Diameter (longest shortest path)\t674  \n",
    "90-percentile effective diameter\t9.7  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset contains 10000 edges\n"
     ]
    }
   ],
   "source": [
    "# import the graph dataset\n",
    "dataset = set()\n",
    "with open(\"web-Stanford.txt\") as f:\n",
    "    for i in range(4, 10000+4): # discard desciptions and pick first 10000 elements to ease the computation\n",
    "        content = next(f).strip().split()\n",
    "        if content[0] != content[1]:\n",
    "            dataset.add((content[0], content[1]))\n",
    "print(f'dataset contains {len(dataset)} edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TRIEST-BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRIEST_BASE(M, dataset=dataset):\n",
    "    \"\"\"\n",
    "    This function estimates number of global triangles by TRIEST_BASE algorithm.\n",
    "    \n",
    "    argument: \n",
    "        M: size of reservoir sample, M>=6\n",
    "        dataset, =dataset defaultly.\n",
    "    return:\n",
    "        number of global triangle count.\n",
    "    \"\"\"\n",
    "    S = set() # edge sample from reservoir sampling\n",
    "    t = 0 # time\n",
    "    tau = 0 # global counter for the estimation of the global number of triangles\n",
    "\n",
    "    \n",
    "    def sample_edge(edge, t, S, tau, M=M):\n",
    "        \"\"\"\n",
    "        This function is the reservoir sampling process.\n",
    "        Notice that each edge item in the sample has equal probability.\n",
    "    \n",
    "        argument:\n",
    "            edge: an arbitrary edge.\n",
    "            t: time instance.\n",
    "            S: edge sample.\n",
    "            M: size of reservoir sample.\n",
    "            tau: global counter.\n",
    "        return:\n",
    "            True or False: whether the input edge will replace an existing edge in the edge sample.\n",
    "            tau: if updated.\n",
    "        \"\"\"\n",
    "        # if t<=M, the edge on the stream at time t \n",
    "        # is deterministically inserted in S\n",
    "        if t <= M:\n",
    "            return [True]\n",
    "    \n",
    "        # if t>M, TRIEST-BASE flips a biased coin with heads probability M/t\n",
    "        # If the outcome is heads, it chooses an existing edge in S uniformly at random,\n",
    "        # remove it and insert the current edge on time t into S \n",
    "        elif random.random() <= (M/t): \n",
    "            del_edge = random.sample(S, 1)[0]\n",
    "            S.remove(del_edge)\n",
    "            #print(1,tau)\n",
    "            tau = update_counters('-', del_edge, S, tau) \n",
    "            #print(2,tau)\n",
    "            return [True, tau]\n",
    "    \n",
    "        # Otherwise S is not modified\n",
    "        return [False]\n",
    "    \n",
    "    \n",
    "    def update_counters(operation, edge, S, tau):\n",
    "        \"\"\"\n",
    "        This function compute neighborhood of vertices and update global and local counters.\n",
    "    \n",
    "        argument:\n",
    "            operation: '+' or '-', means insert or delete respectively.\n",
    "            edge: an arbitrary edge.\n",
    "            S: edge sample.\n",
    "            tau: global counter.    \n",
    "        return:\n",
    "            tau: updated global counter.\n",
    "        \"\"\"\n",
    "        u = edge[0]\n",
    "        v = edge[1]\n",
    "    \n",
    "        # construct neighborhood of u and v respectively\n",
    "        # $ N^S_u = {v in V^(t): (u,v) in S} $\n",
    "        u_neighbor = set()\n",
    "        v_neighbor = set()\n",
    "        for vertices_pair in S:\n",
    "            # neighborhood of u\n",
    "            if u == vertices_pair[0]:\n",
    "                u_neighbor.add(vertices_pair[1])\n",
    "            elif u == vertices_pair[1]:\n",
    "                u_neighbor.add(vertices_pair[0])\n",
    "            # neighborhood of v\n",
    "            if v == vertices_pair[0]:\n",
    "                v_neighbor.add(vertices_pair[1])\n",
    "            elif v == vertices_pair[1]:\n",
    "                v_neighbor.add(vertices_pair[0])\n",
    "        \n",
    "        # construct shared neighborhood of u and v\n",
    "        # $ N^S_u,v = intersection(N^S_u, N^S_v) $\n",
    "        shared_neighbor = set.intersection(u_neighbor, v_neighbor)\n",
    "        #if shared_neighbor != set():\n",
    "        #   print(operation, len(shared_neighbor))\n",
    "    \n",
    "        # update counters\n",
    "        for c in (u_neighbor & v_neighbor):\n",
    "            if operation == '+':\n",
    "                tau += 1\n",
    "                tau_u = len(u_neighbor) + 1 # local counter for a subset of the nodes u in V^(t)\n",
    "                tau_v = len(v_neighbor) + 1 # local counter for a subset of the nodes v in U^(t)\n",
    "                tau_c = len(shared_neighbor) + 1 # local counter for a subset of the nodes in shared neighborhood of u and v\n",
    "            elif operation == '-':\n",
    "                tau -= 1\n",
    "                tau_u = len(u_neighbor) - 1\n",
    "                if tau_u <= 0:\n",
    "                    del tau_u\n",
    "                tau_v = len(v_neighbor) - 1\n",
    "                if tau_v <= 0:\n",
    "                    del tau_v\n",
    "                tau_c = len(shared_neighbor) - 1\n",
    "                if tau_c <= 0:\n",
    "                    del tau_c\n",
    "        return tau\n",
    "    \n",
    "    \n",
    "    for edge in dataset:\n",
    "        #if t%1000 == 0:\n",
    "        #    print(f'element index = {t}, tau = {tau}')\n",
    "            \n",
    "        t += 1 # update time\n",
    "        result = sample_edge(edge, t, S, tau)\n",
    "        if result[0] is True:\n",
    "            S.add(edge)\n",
    "            if len(result) > 1:\n",
    "                tau = result[1] # update tau value of deletion step\n",
    "            tau = update_counters('+', edge, S, tau)  \n",
    "        \n",
    "    epsilon = (t*(t-1)*(t-2)) / (M*(M-1)*(M-2))\n",
    "    if epsilon < 1:\n",
    "        epsilon = 1\n",
    "    return epsilon*tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set M=5000 in the above sampling case and remember the size of the dataset we use is 10000.  \n",
    "We can see that when t<=M, our estimate number of triangles by TRIEST_BASE algorithm is exactly the same as true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute true value:\n",
      "element index = 0, tau = 0\n",
      "element index = 1000, tau = 37\n",
      "element index = 2000, tau = 296\n",
      "element index = 3000, tau = 1002\n",
      "element index = 4000, tau = 2367\n",
      "element index = 5000, tau = 4555\n",
      "element index = 6000, tau = 7557\n",
      "element index = 7000, tau = 11411\n",
      "element index = 8000, tau = 16712\n",
      "element index = 9000, tau = 22707\n",
      "True value is 30190.0.\n",
      "\n",
      "Compute estimate value by reservoir sampling:\n",
      "element index = 0, tau = 0\n",
      "element index = 1000, tau = 37\n",
      "element index = 2000, tau = 296\n",
      "element index = 3000, tau = 1002\n",
      "element index = 4000, tau = 2367\n",
      "element index = 5000, tau = 4555\n",
      "element index = 6000, tau = 4499\n",
      "element index = 7000, tau = 4435\n",
      "element index = 8000, tau = 4475\n",
      "element index = 9000, tau = 4602\n",
      "Estimate value is 38043.41416566627.\n",
      "\n",
      "Error: 7853.414165666269 triangles.\n",
      "Error rate: 0.2601329634205455.\n"
     ]
    }
   ],
   "source": [
    "print('Compute true value:')\n",
    "true_value = TRIEST_BASE(len(dataset)) # M = len(dataset) = 10000\n",
    "print(f'True value is {true_value}.')\n",
    "\n",
    "print('\\nCompute estimate value by reservoir sampling:')\n",
    "estimate_value = TRIEST_BASE(5000) # pick arbitrary M=5000\n",
    "print(f'Estimate value is {estimate_value}.')\n",
    "\n",
    "print(f'\\nError: {abs(estimate_value - true_value)} triangles.')\n",
    "print(f'Error rate: {abs(estimate_value - true_value)/true_value}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiple runs, we hypothesis that the results (estimation of number of global triangles) distributed normally. And if the sample mean is biased compared to the true value, we suppose that the algorithm is somehow biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "estimate_list = []\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    estimate_value = TRIEST_BASE(5000) # pick arbitrary M=5000\n",
    "    estimate_list.append(estimate_value)\n",
    "    \n",
    "mean_value = np.mean(estimate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run TRIEST_BASE for 20 times with M=5000, result list: \n",
      "[35994.79951980792, 38411.52460984394, 41004.30252100841, 38107.43337334934, 40796.24009603842, 35786.73709483794, 38643.59423769508, 37131.140456182475, 38267.48139255703, 38891.66866746699, 36042.81392557023, 39291.7887154862, 41188.357743097244, 35594.67947178872, 34530.360144057624, 38947.685474189675, 38195.45978391357, 37459.23889555823, 37731.32052821129, 38827.64945978392]\n",
      "\n",
      "mean value is 38042.21380552221\n"
     ]
    }
   ],
   "source": [
    "print(f'run TRIEST_BASE for 20 times with M=5000, result list: \\n{estimate_list}')\n",
    "print(f'\\nmean value is {mean_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation of global number of triangles is very sensative to the choice of M.\n",
    "As M tends to the length of the original dataset, the estimation tends to the true value and the variance of results in multiple runs shrinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true value = 30190.0\n",
      "M = 1000, estimate number of global triangles = 61165.07411218834\n",
      "M = 3000, estimate number of global triangles = 37655.9891144502\n",
      "M = 5000, estimate number of global triangles = 36290.88835534214\n",
      "M = 7000, estimate number of global triangles = 33878.99204053664\n",
      "M = 9000, estimate number of global triangles = 30470.151635973678\n"
     ]
    }
   ],
   "source": [
    "print(f'true value = {true_value}')\n",
    "for M in [1000, 3000, 5000, 7000, 9000]:\n",
    "    estimate_value = TRIEST_BASE(M)\n",
    "    print(f'M = {M}, estimate number of global triangles = {estimate_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TRIEST-IMPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRIEST_IMPR(M, dataset=dataset):\n",
    "    \"\"\"\n",
    "    This function estimates number of global triangles by TRIEST_IMPR algorithm.\n",
    "    \n",
    "    argument: \n",
    "        M: size of reservoir sample, M>=6\n",
    "        dataset, =dataset defaultly.\n",
    "    return:\n",
    "        number of global triangle count.\n",
    "    \"\"\"\n",
    "    S = set() # edge sample from reservoir sampling\n",
    "    t = 0 # time\n",
    "    tau = 0 # global counter for the estimation of the global number of triangles\n",
    "\n",
    "    \n",
    "    def sample_edge(edge, t, S, M=M):\n",
    "        \"\"\"\n",
    "        This function is the reservoir sampling process.\n",
    "        Notice that each edge item in the sample has equal probability.\n",
    "    \n",
    "        argument:\n",
    "            edge: an arbitrary edge.\n",
    "            t: time instance.\n",
    "            S: edge sample.\n",
    "            M: size of reservoir sample.\n",
    "        return:\n",
    "            True or False: whether the input edge will replace an existing edge in the edge sample.\n",
    "        \"\"\"\n",
    "        # if t<=M, the edge on the stream at time t \n",
    "        # is deterministically inserted in S\n",
    "        if t <= M:\n",
    "            return True\n",
    "    \n",
    "        # if t>M, TRIEST-BASE flips a biased coin with heads probability M/t\n",
    "        # If the outcome is heads, it chooses an existing edge in S uniformly at random,\n",
    "        # remove it and insert the current edge on time t into S \n",
    "        elif random.random() <= (M/t): \n",
    "            del_edge = random.sample(S, 1)[0]\n",
    "            S.remove(del_edge)\n",
    "            # TRIEST-IMPR never decrements the counters when an edge is removed from S\n",
    "            return True\n",
    "    \n",
    "        # Otherwise S is not modified\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def update_counters(edge, S, tau, t, M=M):\n",
    "        \"\"\"\n",
    "        This function compute neighborhood of vertices and update global and local counters.\n",
    "    \n",
    "        argument:\n",
    "            edge: an arbitrary edge.\n",
    "            S: edge sample.\n",
    "            tau: global counter.  \n",
    "            t: time instance.\n",
    "            M: sample size, default =M.\n",
    "        return:\n",
    "            tau: updated global counter.\n",
    "        \"\"\"\n",
    "        u = edge[0]\n",
    "        v = edge[1]\n",
    "    \n",
    "        # construct neighborhood of u and v respectively\n",
    "        # $ N^S_u = {v in V^(t): (u,v) in S} $\n",
    "        u_neighbor = set()\n",
    "        v_neighbor = set()\n",
    "        for vertices_pair in S:\n",
    "            # neighborhood of u\n",
    "            if u == vertices_pair[0]:\n",
    "                u_neighbor.add(vertices_pair[1])\n",
    "            elif u == vertices_pair[1]:\n",
    "                u_neighbor.add(vertices_pair[0])\n",
    "            # neighborhood of v\n",
    "            if v == vertices_pair[0]:\n",
    "                v_neighbor.add(vertices_pair[1])\n",
    "            elif v == vertices_pair[1]:\n",
    "                v_neighbor.add(vertices_pair[0])\n",
    "        \n",
    "        # construct shared neighborhood of u and v\n",
    "        # $ N^S_u,v = intersection(N^S_u, N^S_v) $\n",
    "        shared_neighbor = set.intersection(u_neighbor, v_neighbor)\n",
    "        #if shared_neighbor != set():\n",
    "        #    print(len(shared_neighbor))\n",
    "    \n",
    "        # update counters\n",
    "        # all the calls to update_counters have operation '+'\n",
    "        # preform a weighted increase using weight\n",
    "        # $ eta^t = max{1, (t-1)(t-2)/(M(M-1))} $\n",
    "        eta = ((t-1)*(t-2)) / (M*(M-1))\n",
    "        if eta < 1:\n",
    "            eta = 1\n",
    "            \n",
    "        for c in (u_neighbor & v_neighbor):\n",
    "            tau += eta\n",
    "            tau_u = len(u_neighbor) + eta # local counter for a subset of the nodes u in V^(t)\n",
    "            tau_v = len(v_neighbor) + eta # local counter for a subset of the nodes v in U^(t)\n",
    "            tau_c = len(shared_neighbor) + eta # local counter for a subset of the nodes in shared neighborhood of u and v\n",
    "        return tau\n",
    "    \n",
    "    \n",
    "    for edge in dataset:\n",
    "        #if t%1000 == 0:\n",
    "        #    print(f'element index = {t}, tau = {tau}')\n",
    "            \n",
    "        t += 1 # update time\n",
    "        tau = update_counters(edge, S, tau, t) # call update_counters unconditionally\n",
    "        \n",
    "        if sample_edge(edge, t, S) == True:\n",
    "            S.add(edge)\n",
    "        \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to test 1.1, we first set M=5000 in the above improved sampling case and the size of the dataset we use is 10000.  \n",
    "We can see that when t<=M, our estimate number of triangles by TRIEST_IMPR algorithm is exactly the same as true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute true value:\n",
      "element index = 0, tau = 0\n",
      "element index = 1000, tau = 37\n",
      "element index = 2000, tau = 296\n",
      "element index = 3000, tau = 1002\n",
      "element index = 4000, tau = 2367\n",
      "element index = 5000, tau = 4555\n",
      "element index = 6000, tau = 7557\n",
      "element index = 7000, tau = 11411\n",
      "element index = 8000, tau = 16712\n",
      "element index = 9000, tau = 22707\n",
      "True value is 30190.\n",
      "\n",
      "Compute estimate value by reservoir sampling:\n",
      "element index = 0, tau = 0\n",
      "element index = 1000, tau = 37\n",
      "element index = 2000, tau = 296\n",
      "element index = 3000, tau = 1002\n",
      "element index = 4000, tau = 2367\n",
      "element index = 5000, tau = 4555\n",
      "element index = 6000, tau = 7610.927455811263\n",
      "element index = 7000, tau = 11942.63614002814\n",
      "element index = 8000, tau = 18017.876664293035\n",
      "element index = 9000, tau = 25427.016077535725\n",
      "Estimate value is 35295.12952070433.\n",
      "\n",
      "Error: 5105.1295207043295 triangles.\n",
      "Error rate: 0.16910001724757634.\n"
     ]
    }
   ],
   "source": [
    "print('Compute true value:')\n",
    "true_value = TRIEST_IMPR(len(dataset)) # M = len(dataset) = 10000\n",
    "print(f'True value is {true_value}.')\n",
    "\n",
    "print('\\nCompute estimate value by reservoir sampling:')\n",
    "estimate_value = TRIEST_IMPR(5000) # pick arbitrary M=4000\n",
    "print(f'Estimate value is {estimate_value}.')\n",
    "\n",
    "print(f'\\nError: {abs(estimate_value - true_value)} triangles.')\n",
    "print(f'Error rate: {abs(estimate_value - true_value)/true_value}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run 20 times of TRIEST_IMPR algorithm with M=5000.  \n",
    "Comparing results with the ones obtained by TRIEST_BASE algorithm, we can see that the variance of improved algorithm is lower and the mean of the improved algorithm is closer to the true value as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "estimate_list_impr = []\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    estimate_value = TRIEST_IMPR(5000) # pick arbitrary M=5000\n",
    "    estimate_list_impr.append(estimate_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true value is 30190.0\n",
      "mean from TRIEST_BASE is 38042.21380552221\n",
      "mean from TRIEST_IMPR is 35072.02691547922\n",
      "variance from TRIEST_BASE is 3170998.664030402\n",
      "variance from TRIEST_IMPR is 423135.8354098646\n"
     ]
    }
   ],
   "source": [
    "mean_base = np.mean(estimate_list)\n",
    "mean_impr = np.mean(estimate_list_impr)\n",
    "var_base = np.var(estimate_list)\n",
    "var_impr = np.var(estimate_list_impr)\n",
    "\n",
    "print(f'true value is {true_value}')\n",
    "print(f'mean from TRIEST_BASE is {mean_base}')\n",
    "print(f'mean from TRIEST_IMPR is {mean_impr}')\n",
    "print(f'variance from TRIEST_BASE is {var_base}')\n",
    "print(f'variance from TRIEST_IMPR is {var_impr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
